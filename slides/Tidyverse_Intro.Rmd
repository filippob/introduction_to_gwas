---
title: "Tidyverse Introduction"
author: "Pietro Franceschi"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


# Introduction

This .Rmd file is a concise summary of a set of advanced R libraries and ideas which can be used for the analysis of large scale datasets.

In particular: 

* Pipes (`%>%`)
* Tabular data
  * `data.frame`, `tibble`, `data.table`
  * data carpentry (`tidyverse`, `data.table`)
  * *long* and *wide* tables 
  * modeling (`broom`)
* Vectorizing operations (`purrr`)
 

```{r}
library(tidyverse)     ## the full tidyverse ecosystem for seamless working with tables
library(broom)         ## a broom to tidy the outcomes of modeling
library(data.table)    ## a less flexible (bit more fast) approach to the manipulation of tabular data
```


# Piping

The overall idea behind piping is to make easy to read a chain of functions. Pipes `%>%` have been introduced in the `magrittr` package but are now a core tool of tidyverse

```{r}
## sequence going from 1 to the square root of 100
one_old <-seq(1,sqrt(100)) 

## The old style work have to be read in an "onion" fashion

one_pipe <- sqrt(100) %>% 
  seq(1,.)

## one_old and one_pipe are exactly equivalent, but the second is by far more easy to read

```

When putting a function in a pile, you refer to "what is coming from the pipe" with a dot `.`

```{r}
## Pipes can be used also to produce plots!

data(iris) ## iris dataset

## note the dot to refer to the iris data.frame which reach the pairs function from the pipe
iris %>% pairs(., col = factor(iris$Species), pch = 19) 
```

### Advantages

* Clear writing
* No need of cluttering the workspace with intermediate objects


### Disadvantages

* no big disadvantages, even if I normally rely on them when I use the console, while in programming tasks I prefer to rely on the "old" onion approach


# Tabular Data

In R tabular data are commonly treated with three different classes of objects

* `data.frame`: old, faithful and the father of almost everything else. A data frame is a list
* `data.table`: basically still a data.frame which have been optimized for efficiency
* `tibble`: is the tidyverse form of data.frames, less efficient than data.table, but more flexyble since it is integrated in the tidy environment

Both data.tables and tibble retains the characteristics of dfs (indexing with square brackets, possible use of $ to get the columns). Importantly, in both cases the row.names attribute has been removed.

These three box of code allow to benchmark the efficiency of the three solution sin reading a relatively big dataset (35 MB)

```{r}
## Base R
system.time(read.csv("athlete_events.csv"))
```

```{r}
# data.table
system.time(fread("athlete_events.csv"))
```

```{r}
# tidyverse
system.time(read_csv("athlete_events.csv"))
```

As it can be seen data.table is almost ten times faster than base R, while tidyverse stays somehow in the middle

tibbles and data.tables also own an improved print method that allows for a more relaxed visualization of the content of the table

```{r}
## read the three tables

baseR <- read.csv("athlete_events.csv")
datat <- fread("athlete_events.csv")
tidyv <- read_csv("athlete_events.csv")
```



```{r}
## this is the data.table printout
datat
```

```{r}
## this is the tidyverse printout
tidyv
```

# Data carpentry in`tidyverse` and `data.table`

## Filtering rows on condition

It is helpful to summarize the data.table slicing approach:

`DT[i, j, by]`
“Take DT, subset rows using i, then calculate j grouped by by”

```{r}
## filtering with data.table 
iris %>% 
  data.table(.) %>%  ## this is needed to transform the iris data.frame to a data.table
  .[Species %in% c("setosa","versicolor"),]

## Note here I'm fitting a data.table slicing into a tidyverse like piping style. The . before the square root refers to the 
## data table coming from the pipe

```

The syntax of tidyverse is slightly more verbose but extremely easy to read


```{r}
iris %>% 
  tibble() %>% 
  filter(Species == "setosa") ## the function filter selects rows on condition

## Note: as we discussed in the lecture, the tibble() call is not necessary, since the coercion to a tibble object
## is performed under the hood by the fact that you are using pipes
```


For the large majority of situations data.tables and tibbles can be used interchangeably, but remember that everything for data table has been optimized for speed. This is true for calculations, selections and sorting

## Selecting columns

If you consider the previous general syntax, you see that selecting columns in dt is fast. Remember the comma!
```{r}
## Extracting several columns as a data.table 
iris %>% 
  data.table(.) %>% 
  .[,list(Species,Sepal.Width)]

## extracting one column as as vector
iris %>% 
  data.table(.) %>% 
  .[,Species]
```

Obviously, the selection of many columns can be performed by using another dot ... just to make life more clear ..


```{r}
## Extracting several columns as a data.table 
iris %>% 
  data.table(.) %>% 
  .[,.(Species,Sepal.Width)]
```

Let's call this, dot deluge ... ;-)

In tidyverse the extraction of a single column as a vector is performed by the `pull` function, while the selection of one or more column resulting in a smaller tibble is performed by the `select` function


```{r}
## pull one column as vector
iris %>% 
  pull(Species)


## select two columns and return a tibble
iris %>% 
  select(Sepal.Length,Species)

```

An interesting and useful characteristic of `select` is the possibility of using a series of selection helpers to identify columns on the base of their properties. See the help of select for a more detailed description

```{r}
## extract all the column with a name starting with sepal
iris %>% 
  tibble() %>% 
  select(starts_with("Sepal"))

## interesting! getting only numeric columns
iris %>% 
  tibble() %>% 
  select(where(~is.numeric(.x)))

```

Unfortunately we have another dot ... 

Note: the writing `~is.numeric(x)` could seem wired. This is a special shortcut to construct _functionals_. Tidysomething will transform formulas starting with `~` into functions. 

There are shorthands to refer to their arguments. For functions with one argument you can use the dot! For one or two (`.x` and `.y`), for an arbitrary number of arguments `..1`,`..2`, `..3`, etc.

So in our case, the following three constructs are equivalent

```{r}
iris %>% 
  select(where(function(c) is.numeric(c)))

iris %>% 
  select(where(~is.numeric(.x)))

iris %>% 
  select(where(~is.numeric(.)))

iris %>% 
  select(where(~is.numeric(..1)))


```

## Creating new columns or mutating existing ones

Creating new columns on the bases of the one present in our dataset is one of the most useful and common tasks of data carpentry.
If you look to it in abstract, also mutating the content of an existing column fits in the previous reasoning: I'm creating a new column with a name which is identical to the old one ... 

In DT, new columns are created by using the `:=` operator in the second "placeholder" of the call
```{r}
## Create a column with the ration between sepal lenght and sepal width
new_dt_col <- iris %>% 
  data.table(.) %>% 
  .[,myratio := Sepal.Length/Sepal.Width]


## Create multiple columns

new_dt_col <- iris %>% 
  data.table(.) %>% 
  .[,c("myratio","myratio1") := list(Sepal.Length/Sepal.Width, Petal.Length/Petal.Width)]

```


In TB there is specific function `mutate` which can be piped to create or manipulate the columns


```{r}
## here the creation!
nef_tb_col <- iris %>% 
  mutate(myratio = Sepal.Length/Sepal.Width)

## multiple columns can be created inside the same mutate call by using commas

```

As usual the DT syntax is more compact, the TB syntax is more easy to read. But DT is by far more efficient!

In tidyverse, the combination of selectors and mutate can be used to apply some sort of transformation to a bunch of columns, To do that, `mutate` have to be combined with `across`. The following example clearly shows the idea:

```{r}
## Suppose I want to calculate the logarithm of all the numeric columns in the iris dataset ...

iris %>% 
  mutate(across(where(~is.numeric(.x)),~log10(.x), .names = "log_{.col}"))

## Here:
## where is used to select the columns which are numeric
## across is used to mutate on all these columns
## and there is a beautiful ~ and . deluge ;-)
## the .names argument allows you to specify a set of new names ... {.col} refers to the old names ...

```

## Perform operations on subgroups of samples (lines)

The last type of operations I want to touch on this flyby, are the one meant to calculate some quantity from groups of samples (rows). 
This is normally handy when you want to calculate summary statistics over a large table of samples. 


In DT this operation is performed combining what we heve done before with the `by` argument

```{r}
## Calculate the average of sepal length on the three species

## Summarising the output as a data.table
iris_mean_dt <- iris %>% 
  data.table(.) %>% 
  .[,list(myavg = mean(Sepal.Length)), by = Species]


## Creating a new column with the separate averages "recycled". I.e the columns of averages is of full length
iris_mean_newcol <- iris %>% 
  data.table(.) %>% 
  .[,myavg := mean(Sepal.Length), by = Species]

```


in the case of TB, "by group" operations are performed by using the `group_by` function, often combined with `summarize`

```{r}
## this does what we have just done ...
iris %>% 
  group_by(Species) %>% 
  summarise(myratio = mean(Sepal.Width), sd = sd(Sepal.Width))

## note that I have here two summary functions
```

Group_by can also be combined with `mutate()` to mirror the "recycling" behavior of dt

```{r}
## here, for example, I'm adding a column with the number of samples for each group.

iris %>% 
  group_by(Species) %>% 
  mutate(nsamples = length(Species))
```
